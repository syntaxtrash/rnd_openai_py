{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate\n",
    "\n",
    "Sending a request using PromptTemplate example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['adjective', 'content'] template='Tell me a {adjective} joke about {content}.' \n",
      "\n",
      "Prompt:  Tell me a funny joke about chickens.\n",
      "Response:  Why did the chicken join a band?\n",
      "\n",
      "Because it had the drumsticks!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "# or\n",
    "# prompt_template = PromptTemplate(\n",
    "# input_variables=[\"adjective\", \"content\"],\n",
    "# template = \"Tell me a {adjective} joke about {content}.\")\n",
    "\n",
    "print(prompt_template, \"\\n\");\n",
    "\n",
    "prompt_format = prompt_template.format(adjective=\"funny\", content=\"chickens\")\n",
    "# or using .format_prompt\n",
    "# prompt_format = prompt_template.format_prompt(adjective=\"funny\", content=\"chickens\")\n",
    "\n",
    "response = llm.invoke(prompt_format)\n",
    "\n",
    "print(\"Prompt: \" , prompt_format)\n",
    "print(\"Response: \", response.content)\n",
    "\n",
    "# https://python.langchain.com/docs/modules/model_io/prompts/quick_start#prompttemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The template supports any number of variables, including no variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  Tell me a joke\n",
      "Response:  Why did the scarecrow win an award? Because he was outstanding in his field!\n"
     ]
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template(\"Tell me a joke\")\n",
    "prompt_format = prompt_template.format()\n",
    "\n",
    "response = llm.invoke(prompt_format)\n",
    "\n",
    "print(\"Prompt: \" , prompt_format)\n",
    "print(\"Response: \", response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String prompt composition\n",
    "When working with string prompts, each template is joined together. You can work with either prompts directly or strings (with the requirement that the first element in the list must be a prompt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  Tell me a joke about sports, make it funny and in english\n",
      "Response:  Why did the golfer bring two pairs of pants to the game?\n",
      "\n",
      "In case he got a hole in one!\n"
     ]
    }
   ],
   "source": [
    "prompt_template = (\n",
    "    PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "    + \", make it funny \"\n",
    "    + \"and in {language}\"\n",
    ")\n",
    "prompt_format = prompt_template.format(topic=\"sports\", language=\"english\")\n",
    "\n",
    "response = llm.invoke(prompt_format)\n",
    "\n",
    "print(\"Prompt: \", prompt_format)\n",
    "print(\"Response: \", response.content)\n",
    "\n",
    "# https://python.langchain.com/docs/modules/model_io/prompts/composition#string-prompt-composition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
