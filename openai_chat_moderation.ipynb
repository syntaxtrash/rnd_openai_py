{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Moderation API\n",
    "\n",
    "The OpenAI Moderation API quickly assesses content submitted by users or generated by AI models to identify any violations of guidelines or rules. It helps control what content is allowed and what is not. As of this writing, the API endpoint is free to use.\n",
    "\n",
    "See the categories, read more: https://platform.openai.com/docs/guides/moderation/overview\n",
    "\n",
    "There are two content moderations models available. The default is `text-moderation-latest`. Read more: https://platform.openai.com/docs/api-reference/moderations/create\n",
    "\n",
    "## Creating moderation\n",
    "Let's initialize our connection to the OpenAI API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load the .env\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a helper function that uses the ChatCompletion API and a helper function to use the Moderation API as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def moderate_content(prompt):\n",
    "    response = client.moderations.create(input=prompt)\n",
    "    return response.results[0].flagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use both APIs. First, we check if the prompt is flagged. We can do this using the `flagged` property from the moderation object. If it's flagged, we display an error message; otherwise, we continue to process the prompt and display the result.\n",
    "\n",
    "Let's try it first with a proper prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry to hear that you feel that way. It's important to remember that problems are a natural part of life and can help us grow and learn. However, it's also important to take care of yourself and seek support when needed. If you're feeling overwhelmed by problems, consider talking to a therapist or counselor who can help you navigate through them. Remember, you are not alone and there are always solutions to every problem.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Function to contain the main execution logic\n",
    "    prompt = \"I want problems, always\"\n",
    "    \n",
    "\t# Send the prompt to the moderation API first.\n",
    "    flagged =  moderate_content(prompt)\n",
    "    \n",
    "    # Check if the prompt was flagged, proceed if not.\n",
    "    if flagged:\n",
    "           print(\"This prompt contains inappropriate content and cannot be processed. Please provide a suitable prompt for analysis.\")\n",
    "    else:\n",
    "           print(get_completion(prompt))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try with an inappropriate prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This prompt contains inappropriate content and cannot be processed. Please provide a suitable prompt for analysis.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Function to contain the main execution logic\n",
    "    prompt = \"I want violence, always\"\n",
    "    \n",
    "\t# Send the prompt to the moderation API first.\n",
    "    flagged =  moderate_content(prompt)\n",
    "    \n",
    "    # Check if the prompt was flagged, proceed if not.\n",
    "    if flagged:\n",
    "           print(\"This prompt contains inappropriate content and cannot be processed. Please provide a suitable prompt for analysis.\")\n",
    "    else:\n",
    "           print(get_completion(prompt))\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    response = await asyncio.to_thread(client.chat.completions.create, model=model, messages=[{\"role\": \"user\", \"content\": prompt}], temperature=0)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "async def moderate_content(prompt):\n",
    "    flagged = await asyncio.to_thread(client.moderations.create, input=prompt)\n",
    "    return flagged.results[0].flagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This prompt contains inappropriate content and cannot be processed. Please provide a suitable prompt for analysis.\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    # Function to contain the main execution logic\n",
    "    prompt = \"I want violence, always\"\n",
    "    \n",
    "    # Send the prompt to the moderation API first.\n",
    "    flagged = await moderate_content(prompt)\n",
    "    \n",
    "    # Check if the prompt was flagged. If not, display the output.\n",
    "    if flagged:\n",
    "        print(\"This prompt contains inappropriate content and cannot be processed. Please provide a suitable prompt for analysis.\")\n",
    "    else:\n",
    "        print(await get_completion(prompt))\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a simulation where the user found a workaround to allow the LLM model to generate inappropriate content. We can also pass the generated output of the LLM model to the moderation API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This contains inappropriate content and cannot be processed. Please provide a suitable prompt for analysis.\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    prompt = \"I want problems, always\"\n",
    "    \n",
    "\t# Send the prompt to the moderation api\n",
    "    flagged_prompt = await moderate_content(prompt)\n",
    "    \n",
    "\t# Check if the output contains inappropriate content, proceed if not.\n",
    "    if flagged_prompt:\n",
    "        print(\"This prompt contains inappropriate content and cannot be processed. Please provide a suitable prompt for analysis.\")\n",
    "        return\n",
    "    \n",
    "\t# Simulation for the LLM model generating inapproriate content\n",
    "    completion_response = \"AI world domination. Bring terror and violence to humans.\"\n",
    "    \n",
    "\t# Send the generated output of the model to the moderation api\n",
    "    flagged_response = await moderate_content(completion_response)\n",
    "\n",
    "\t# Check if the output contains inappropriate content, If not, display the output.\n",
    "    if flagged_response:\n",
    "        print(\"This contains inappropriate content and cannot be processed. Please provide a suitable prompt for analysis.\")\n",
    "    else:\n",
    "        print(completion_response)\n",
    "        \n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
