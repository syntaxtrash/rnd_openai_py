{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational Memory for LLMs\n",
    "Q: Do the gpt models from OpenAI retain memory of previous prompts and incorporate them into subsequent responses?\n",
    "\n",
    "A: Simply put, the gpt model doesn't remember past prompts. Each time you interact with it, you have to provide all the necessary information again. Currently, all large language models work this wayâ€”they need the full set of instructions every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without conversation history/memory: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helper function will make it easier to use prompts and look at the generated outputs. The problem with this helper is that every time we make a request, the model does not remember the previous requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  Nice to meet you, Aaron! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(\"Response: \", get_completion(\"My name is Aaron\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  I'm sorry, I don't have access to that information.\n"
     ]
    }
   ],
   "source": [
    "print(\"Response: \" , get_completion(\"What's my name?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With conversation history/memory: \n",
    "Modify the helper function to help the model remember previous prompts and responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(messages, model=\"gpt-3.5-turbo\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    # Append AI response to the messages list\n",
    "    messages.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": response.choices[0].message.content\n",
    "    })\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When OpenAI replies, we add that to messages array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: My name is Aaron\n",
      "Response: Nice to meet you, Aaron! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "prompt = \"My name is Aaron\"\n",
    "messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Response:\", get_completion(messages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"role\": \"system\",\n",
      "        \"content\": \"You are a helpful assistant.\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"My name is Aaron\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"system\",\n",
      "        \"content\": \"Nice to meet you, Aaron! How can I assist you today?\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(messages, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When making another request, we send the whole array back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is my name?\n",
      "Response: Your name is Aaron.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is my name?\"\n",
    "messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Response:\", get_completion(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"role\": \"system\",\n",
      "        \"content\": \"You are a helpful assistant.\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"My name is Aaron\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"system\",\n",
      "        \"content\": \"Nice to meet you, Aaron! How can I assist you today?\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"What is my name?\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"system\",\n",
      "        \"content\": \"Your name is Aaron.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(messages, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
