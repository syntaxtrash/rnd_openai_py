{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL)\n",
    "- LangChain Expression Language or LCEL is a declarative way to easily compose chains together. \n",
    "- Any chain constructed this way will automatically have full sync, async, and streaming support.\n",
    "- Create custom chains.\n",
    "- Read more: https://python.langchain.com/v0.1/docs/expression_language/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCEL Syntax/Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In typical LangChain we would use a chain like in our example of using `LLMChain` https://github.com/syntaxtrash/rnd_openai_py/blob/main/langchain_chains.ipynb \\\n",
    "\n",
    "But since version 0.1.17, LLMChain is deprecated and considered a [Legacy Chain](https://python.langchain.com/v0.1/docs/modules/chains/#legacy-chains) \\\n",
    "Read more: https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html\n",
    "\n",
    "With LCEL, the format is different, rather than relying on Chains (like LLMChain) we simple chain together each runnable component using the pipe operator `|`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, let's initialize our connection to OpenAI with LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create the prompt template and the format of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# StrOutputParser is a simple output parser that just converts the output of a language model (LLM or ChatModel) into a string. \n",
    "# It basically just gets the value of the .content property in the output and display it as string. \n",
    "# Read more: https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html\n",
    "\n",
    "# Create the string template\n",
    "string_template = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{translate}```\n",
    "\"\"\"\n",
    "\n",
    "# Create a chat prompt template from a string template\n",
    "prompt_template = ChatPromptTemplate.from_template(string_template)\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Lastly, Create our own chain with LCEL syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Good morning! Kamusta ka today? ðŸ˜Š\"\n"
     ]
    }
   ],
   "source": [
    "our_custom_chain = prompt_template | llm | output_parser\n",
    "\n",
    "# Uses the pipe '|' operator\n",
    "response = our_custom_chain.invoke({\"style\": \"Taglish, playful and friendly tone\", \"translate\": \"Good morning! How are you today?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See tha comparison of with and without LCEL : https://python.langchain.com/v0.1/docs/expression_language/why/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
