{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Memory for LLMs\n",
    "Q: Do the GTP models from OpenAI retain memory of previous prompts and incorporate them into subsequent responses?\n",
    "\n",
    "A: The GPT models are stateless, meaning the gpt model doesn't remember past prompts. Each time we interact with it, we have to provide all the necessary information again. Currently, all large language models work this wayâ€”they need the full set of instructions every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load the .env\n",
    "load_dotenv(find_dotenv())\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without conversation history/memory: \n",
    "With our current helper function. The model will not remember previous prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  Nice to meet you, Aaron! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(\"Response: \", get_completion(\"My name is Aaron\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  I'm sorry, I do not have access to personal information such as your name.\n"
     ]
    }
   ],
   "source": [
    "print(\"Response: \" , get_completion(\"What's my name?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With conversation history/memory: \n",
    "Modify the helper function to help the model remember previous prompts and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # This will be used to format the response into JSON format for better readability.\n",
    "\n",
    "def get_completion(messages, model=\"gpt-3.5-turbo\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    # Append AI response to the messages list\n",
    "    messages.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": response.choices[0].message.content\n",
    "    })\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When OpenAI replies, we add that to messages array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: My name is Aaron\n",
      "Response: Nice to meet you, Aaron! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "prompt = \"My name is Aaron\"\n",
    "messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Response:\", get_completion(messages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"role\": \"system\",\n",
      "        \"content\": \"You are a helpful assistant.\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"My name is Aaron\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Nice to meet you, Aaron! How can I assist you today?\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# See the response in better format.\n",
    "print(json.dumps(messages, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When making another request, we send the whole array back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is my name?\n",
      "Response: Your name is Aaron.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is my name?\"\n",
    "messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Response:\", get_completion(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"role\": \"system\",\n",
      "        \"content\": \"You are a helpful assistant.\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"My name is Aaron\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Nice to meet you, Aaron! How can I assist you today?\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"What is my name?\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Your name is Aaron.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(messages, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
